{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv' does not exist: b'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e9579e436904>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## reading the files and loading them into dataframes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/sample_submission.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/unlinked_masked_final.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv' does not exist: b'C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv'"
     ]
    }
   ],
   "source": [
    "## reading the files and loading them into dataframes.\n",
    "train = pd.read_csv('C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Train.csv')\n",
    "test= pd.read_csv('C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/Test.csv')\n",
    "sample = pd.read_csv('C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/sample_submission.csv')\n",
    "mask = pd.read_csv('C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/unlinked_masked_final.csv')\n",
    "variabs = pd.read_csv('C:/Users/Amine/Desktop/Standard Bank Tech Impact Challenge Xente credit scoring challenge/VariableDefinitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transform dates types from 'object' to 'datetime'\n",
    "train.TransactionStartTime=pd.to_datetime(train.TransactionStartTime)\n",
    "test.TransactionStartTime=pd.to_datetime(test.TransactionStartTime)\n",
    "train.IssuedDateLoan=pd.to_datetime(train.IssuedDateLoan)\n",
    "test.IssuedDateLoan=pd.to_datetime(test.IssuedDateLoan)\n",
    "train.PaidOnDate=pd.to_datetime(train.PaidOnDate)\n",
    "train.DueDate=pd.to_datetime(train.DueDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating variables to transfer the information contained in the rows of the same transaction.\n",
    "train['Number_Of_Split_Payments'] = 0 ## this is a count on the number of payments on the same loan. It will take a 0 for singled-rowed transactions, 1+ for multi-row transacs.\n",
    "#train['Sum_Diff_Time_Payments'] = 0 ## I'm thinking of summing the delays between all payments made on a loan. It will take 0 for loans paid in a single time, 1+ for multiple payments on the same loan.\n",
    "test['Number_Of_Split_Payments']=0\n",
    "#test['Sum_Diff_Time_Payments']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating the feature : number of split payments on a loan.\n",
    "train['Number_Of_Split_Payments']=train['TransactionId'].map(train.groupby('TransactionId').agg('count')['Number_Of_Split_Payments'])\n",
    "test['Number_Of_Split_Payments']=test['TransactionId'].map(test.groupby('TransactionId').agg('count')['Number_Of_Split_Payments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train[(train.TransactionId=='TransactionId_703')|((train.TransactionId=='TransactionId_927'))].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets drop the duplicate rows with the same transaction ID and keep the last one. (as in with the latest payment installment )\n",
    "train.drop_duplicates(subset=['TransactionId'],keep='last',inplace=True)\n",
    "test.drop_duplicates(subset=['TransactionId'],keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['CountryCode','Currency','CurrencyCode','SubscriptionId','ProviderId','ChannelId'],axis=1,inplace=True)\n",
    "test.drop(['CountryCode','CurrencyCode','SubscriptionId','ProviderId','ChannelId'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Count_Rejected_Loans'] = train['CustomerId'].map(train[train.TransactionStatus==0].groupby('CustomerId').LoanId.size())\n",
    "test['Count_Rejected_Loans'] = test['CustomerId'].map(train[train.TransactionStatus==0].groupby('CustomerId').LoanId.size())\n",
    "## then we should impute the columns of customers that were not found in the rejected list with 0 as in they have never been rejected.\n",
    "train.Count_Rejected_Loans.fillna(value=0,inplace=True)\n",
    "test.Count_Rejected_Loans.fillna(value=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## group train/test together to perform cumulative count\n",
    "all_data=pd.concat((train,test)).copy()\n",
    "## Initialize and compute values for the new feature\n",
    "all_data['Cumulative_Reject']=0\n",
    "all_data.loc[all_data.TransactionStatus==0,'Cumulative_Reject'] = all_data[all_data.TransactionStatus==0].groupby('CustomerId').cumcount()\n",
    "## Separate all_data into train and test\n",
    "train1=all_data[:len(train)]\n",
    "test1=all_data[len(train):]\n",
    "train['Cumulative_Reject']=0\n",
    "test['Cumulative_Reject']=0\n",
    "train['Cumulative_Reject']=train1['Cumulative_Reject']\n",
    "test['Cumulative_Reject']=test1['Cumulative_Reject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purchasestats=train[train.TransactionStatus==0].groupby('CustomerId').Value.agg(('mean','std','min','max'))\n",
    "train['prchs_mean']=train['CustomerId'].map(purchasestats['mean'])\n",
    "train['prchs_std']=train['CustomerId'].map(purchasestats['std'])\n",
    "train['prchs_max']=train['CustomerId'].map(purchasestats['max'])\n",
    "train['prchs_min']=train['CustomerId'].map(purchasestats['min'])\n",
    "test['prchs_mean']=test['CustomerId'].map(purchasestats['mean'])\n",
    "test['prchs_std']=test['CustomerId'].map(purchasestats['std'])\n",
    "test['prchs_max']=test['CustomerId'].map(purchasestats['max'])\n",
    "test['prchs_min']=test['CustomerId'].map(purchasestats['min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuegroups=mask.groupby('CustomerId').Value.agg(('mean','std','min','max','count'))\n",
    "train['mean_cus_transac']=train['CustomerId'].map(valuegroups['mean'])\n",
    "train['std_cus_transac']=train['CustomerId'].map(valuegroups['std'])\n",
    "train['min_cus_transac']=train['CustomerId'].map(valuegroups['min'])\n",
    "train['max_cus_transac']=train['CustomerId'].map(valuegroups['max'])\n",
    "train['count_cus_transac']=train['CustomerId'].map(valuegroups['count'])\n",
    "test['mean_cus_transac']=test['CustomerId'].map(valuegroups['mean'])\n",
    "test['std_cus_transac']=test['CustomerId'].map(valuegroups['std'])\n",
    "test['min_cus_transac']=test['CustomerId'].map(valuegroups['min'])\n",
    "test['max_cus_transac']=test['CustomerId'].map(valuegroups['max'])\n",
    "test['count_cus_transac']=test['CustomerId'].map(valuegroups['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Day_Of_Week']= train.TransactionStartTime.dt.weekday\n",
    "test['Day_Of_Week'] =test.TransactionStartTime.dt.weekday\n",
    "train['Day_in_month']=train.TransactionStartTime.dt.day\n",
    "test['Day_in_month']=test.TransactionStartTime.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "datemin = date(2018,9,21)\n",
    "datemax= date(2019,7,17)\n",
    "(datemax-datemin).days\n",
    "datesinc=pd.DataFrame(columns=['date','inc_value'])\n",
    "datesinc.loc[0,'inc_value']=1\n",
    "datesinc.loc[0,'date']=datemin\n",
    "from datetime import timedelta\n",
    "for i in range(2,301):\n",
    "    datesinc.loc[i-1,'inc_value']=i\n",
    "    datesinc.loc[i-1,'date']=datemin + timedelta(days=i-1)\n",
    "train['inc_value_date']=train.TransactionStartTime.dt.date.map(datesinc.set_index('date').inc_value)\n",
    "test['inc_value_date']=test.TransactionStartTime.dt.date.map(datesinc.set_index('date').inc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.inc_value_date = train.inc_value_date.astype(np.int64)\n",
    "test.inc_value_date = test.inc_value_date.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=train[(train.TransactionStatus==1)&(train.TransactionStartTime<train.DueDate)].groupby('CustomerId').agg(('count','mean','std','min','max')).Value\n",
    "#train['number_transac_before_due']=train['CustomerId'].map(aa['count'])\n",
    "train['before_due_mean'] = train['CustomerId'].map(aa['mean'])\n",
    "train['before_due_std'] = train['CustomerId'].map(aa['std'])\n",
    "train['before_due_min'] = train['CustomerId'].map(aa['min'])\n",
    "train['before_due_max'] = train['CustomerId'].map(aa['max'])\n",
    "test['before_due_mean'] = test['CustomerId'].map(aa['mean'])\n",
    "test['before_due_std'] = test['CustomerId'].map(aa['std'])\n",
    "test['before_due_min'] = test['CustomerId'].map(aa['min'])\n",
    "test['before_due_max'] = test['CustomerId'].map(aa['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Cnt_missed_payment']=0\n",
    "train.loc[train.DueDate<train.PaidOnDate,'Cnt_missed_payment']=train[train.DueDate<train.PaidOnDate].groupby('CustomerId').cumcount()\n",
    "test['Cnt_missed_payment']=test['CustomerId'].map(train.groupby('CustomerId').agg('max').Cnt_missed_payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train['IssuedDateLoan']=pd.to_datetime(train.IssuedDateLoan)\n",
    "#train['Time_till_first_transac_onloan'] = (train['TransactionStartTime']-train['IssuedDateLoan']).astype('timedelta64[h]')\n",
    "#train[(train['TransactionStartTime']-train['IssuedDateLoan']).astype('timedelta64[h]')<0]\n",
    "#train['Factor_Loan']= train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[train.IsDefaulted.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-976872268292>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIsDefaulted\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train[train.IsDefaulted==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:,'new_customer']=0\n",
    "test.loc[:,'new_customer']=0\n",
    "train.loc[train.mean_cus_transac.isnull(),'new_customer']=1\n",
    "test.loc[test.mean_cus_transac.isnull(),'new_customer']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [#'CustomerId', #'TransactionStartTime', \n",
    "            'Value', #'Amount',\n",
    "       #'TransactionId', \n",
    "            #'BatchId', \n",
    "             #'ProductId',\n",
    "    'mean_cus_transac','std_cus_transac', 'min_cus_transac', 'max_cus_transac', \n",
    "       #'ProductCategory', #'TransactionStatus', \n",
    "            #'IssuedDateLoan',\n",
    "       #'LoanId', , 'LoanApplicationId', 'ThirdPartyId',\n",
    "       #'Number_Of_Split_Payments', \n",
    "        #    'Count_Rejected_Loans', \n",
    "           #'Cumulative_Reject',\n",
    "       #'prchs_mean', 'prchs_std',\n",
    "    'prchs_max', 'prchs_min', \n",
    "         #   'InvestorId',\n",
    "         #   'Day_Of_Week',\n",
    "    'Day_in_month',#,'new_customer' \n",
    "    #'inc_value_date'\n",
    "    #'before_due_mean'#, 'before_due_std',\n",
    "       'before_due_min', 'before_due_max', \n",
    "            'count_cus_transac'#,'Cnt_missed_payment'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oce = ce.OneHotEncoder(cols=['ProductId'])#,'ProductCategory','InvestorId'])\n",
    "#tce = ce.TargetEncoder(cols=['CustomerId'],smoothing=40,min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[features]\n",
    "X_test = test[features]\n",
    "y=train.IsDefaulted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(X,y,test_size=0.2,stratify=y,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = oce.fit_transform(X_train)\n",
    "#X_train = tce.fit_transform(X_train,y_train)\n",
    "#X_val = oce.transform(X_val)\n",
    "#X_val = tce.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9894667544437129\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=3,colsample_bytree=0.6,min_child_weight=10,learning_rate=0.25,n_estimators=100,objective = \"binary:logistic\")\n",
    "xgb.fit(X_train,y_train)\n",
    "val_pred=xgb.predict_proba(X_val)[:,1]\n",
    "print(roc_auc_score(y_val,val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = oce.fit_transform(X)\n",
    "#X = tce.fit_transform(X_train,y_train)\n",
    "#X_test = test[features]\n",
    "#X_test = oce.transform(X_test)\n",
    "#X_test = tce.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X,y)\n",
    "test_pred=xgb.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.DataFrame(columns=['TransactionId','IsDefaulted'])\n",
    "sample_submission['TransactionId'] = test['TransactionId']\n",
    "sample_submission['IsDefaulted'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('C:/Users/Amine/Desktop/STB_XGB_Thleth8.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Amount</th>\n",
       "      <th>TransactionStatus</th>\n",
       "      <th>AmountLoan</th>\n",
       "      <th>IsFinalPayBack</th>\n",
       "      <th>IsThirdPartyConfirmed</th>\n",
       "      <th>IsDefaulted</th>\n",
       "      <th>Number_Of_Split_Payments</th>\n",
       "      <th>Count_Rejected_Loans</th>\n",
       "      <th>Cumulative_Reject</th>\n",
       "      <th>...</th>\n",
       "      <th>max_cus_transac</th>\n",
       "      <th>Day_Of_Week</th>\n",
       "      <th>Day_in_month</th>\n",
       "      <th>inc_value_date</th>\n",
       "      <th>before_due_mean</th>\n",
       "      <th>before_due_std</th>\n",
       "      <th>before_due_min</th>\n",
       "      <th>before_due_max</th>\n",
       "      <th>Cnt_missed_payment</th>\n",
       "      <th>new_customer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1073.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1.043000e+03</td>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1.153000e+03</td>\n",
       "      <td>1153.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.128621e+04</td>\n",
       "      <td>-2.115861e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.043774e+04</td>\n",
       "      <td>0.934952</td>\n",
       "      <td>0.980052</td>\n",
       "      <td>0.061578</td>\n",
       "      <td>1.290546</td>\n",
       "      <td>1.794449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52570.672880</td>\n",
       "      <td>2.680833</td>\n",
       "      <td>16.111015</td>\n",
       "      <td>124.830876</td>\n",
       "      <td>2.127673e+04</td>\n",
       "      <td>7.890890e+03</td>\n",
       "      <td>1.552366e+04</td>\n",
       "      <td>3.183914e+04</td>\n",
       "      <td>0.464874</td>\n",
       "      <td>0.069384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.849843e+04</td>\n",
       "      <td>9.848352e+04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.419850e+04</td>\n",
       "      <td>0.246717</td>\n",
       "      <td>0.139882</td>\n",
       "      <td>0.240493</td>\n",
       "      <td>1.062977</td>\n",
       "      <td>3.567100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74088.996842</td>\n",
       "      <td>1.846202</td>\n",
       "      <td>8.884179</td>\n",
       "      <td>39.034529</td>\n",
       "      <td>8.305972e+04</td>\n",
       "      <td>7.806406e+04</td>\n",
       "      <td>6.535204e+04</td>\n",
       "      <td>1.228537e+05</td>\n",
       "      <td>1.381559</td>\n",
       "      <td>0.254217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>-2.500000e+06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>-6.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.095000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>1.782609e+03</td>\n",
       "      <td>8.555886e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>-2.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.228000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>26000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>3.193750e+03</td>\n",
       "      <td>1.962430e+03</td>\n",
       "      <td>1.000000e+03</td>\n",
       "      <td>9.500000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>-1.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.300000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>7.225732e+03</td>\n",
       "      <td>3.742979e+03</td>\n",
       "      <td>2.000000e+03</td>\n",
       "      <td>1.350000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>-1.000000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.760000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>1.250250e+06</td>\n",
       "      <td>1.767413e+06</td>\n",
       "      <td>1.200000e+06</td>\n",
       "      <td>2.500000e+06</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Value        Amount  TransactionStatus    AmountLoan  \\\n",
       "count  1.153000e+03  1.153000e+03             1153.0  1.153000e+03   \n",
       "mean   2.128621e+04 -2.115861e+04                1.0  1.043774e+04   \n",
       "std    9.849843e+04  9.848352e+04                0.0  8.419850e+04   \n",
       "min    1.000000e+02 -2.500000e+06                1.0  5.000000e+01   \n",
       "25%    1.000000e+03 -6.000000e+03                1.0  1.095000e+03   \n",
       "50%    2.000000e+03 -2.000000e+03                1.0  2.228000e+03   \n",
       "75%    6.000000e+03 -1.000000e+03                1.0  6.300000e+03   \n",
       "max    2.500000e+06 -1.000000e+02                1.0  2.760000e+06   \n",
       "\n",
       "       IsFinalPayBack  IsThirdPartyConfirmed  IsDefaulted  \\\n",
       "count     1153.000000            1153.000000  1153.000000   \n",
       "mean         0.934952               0.980052     0.061578   \n",
       "std          0.246717               0.139882     0.240493   \n",
       "min          0.000000               0.000000     0.000000   \n",
       "25%          1.000000               1.000000     0.000000   \n",
       "50%          1.000000               1.000000     0.000000   \n",
       "75%          1.000000               1.000000     0.000000   \n",
       "max          1.000000               1.000000     1.000000   \n",
       "\n",
       "       Number_Of_Split_Payments  Count_Rejected_Loans  Cumulative_Reject  ...  \\\n",
       "count               1153.000000           1153.000000             1153.0  ...   \n",
       "mean                   1.290546              1.794449                0.0  ...   \n",
       "std                    1.062977              3.567100                0.0  ...   \n",
       "min                    1.000000              0.000000                0.0  ...   \n",
       "25%                    1.000000              0.000000                0.0  ...   \n",
       "50%                    1.000000              0.000000                0.0  ...   \n",
       "75%                    1.000000              1.000000                0.0  ...   \n",
       "max                   12.000000             16.000000                0.0  ...   \n",
       "\n",
       "       max_cus_transac  Day_Of_Week  Day_in_month  inc_value_date  \\\n",
       "count      1073.000000  1153.000000   1153.000000     1153.000000   \n",
       "mean      52570.672880     2.680833     16.111015      124.830876   \n",
       "std       74088.996842     1.846202      8.884179       39.034529   \n",
       "min         500.000000     0.000000      1.000000       28.000000   \n",
       "25%       19000.000000     1.000000      8.000000       89.000000   \n",
       "50%       26000.000000     3.000000     16.000000      131.000000   \n",
       "75%       50000.000000     4.000000     24.000000      157.000000   \n",
       "max     1000000.000000     6.000000     31.000000      192.000000   \n",
       "\n",
       "       before_due_mean  before_due_std  before_due_min  before_due_max  \\\n",
       "count     1.153000e+03    1.043000e+03    1.153000e+03    1.153000e+03   \n",
       "mean      2.127673e+04    7.890890e+03    1.552366e+04    3.183914e+04   \n",
       "std       8.305972e+04    7.806406e+04    6.535204e+04    1.228537e+05   \n",
       "min       5.000000e+02    0.000000e+00    1.000000e+02    5.000000e+02   \n",
       "25%       1.782609e+03    8.555886e+02    5.000000e+02    5.000000e+03   \n",
       "50%       3.193750e+03    1.962430e+03    1.000000e+03    9.500000e+03   \n",
       "75%       7.225732e+03    3.742979e+03    2.000000e+03    1.350000e+04   \n",
       "max       1.250250e+06    1.767413e+06    1.200000e+06    2.500000e+06   \n",
       "\n",
       "       Cnt_missed_payment  new_customer  \n",
       "count         1153.000000   1153.000000  \n",
       "mean             0.464874      0.069384  \n",
       "std              1.381559      0.254217  \n",
       "min              0.000000      0.000000  \n",
       "25%              0.000000      0.000000  \n",
       "50%              0.000000      0.000000  \n",
       "75%              0.000000      0.000000  \n",
       "max             12.000000      1.000000  \n",
       "\n",
       "[8 rows x 27 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
